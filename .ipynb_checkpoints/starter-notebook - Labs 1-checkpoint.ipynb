{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d7f3214",
   "metadata": {
    "papermill": {
     "duration": 0.036252,
     "end_time": "2021-08-13T07:16:36.548737",
     "exception": false,
     "start_time": "2021-08-13T07:16:36.512485",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Telecom Churn Prediction - Starter Notebook\n",
    "\n",
    "**Author:** Akshay Sehgal (www.akshaysehgal.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5052e4",
   "metadata": {
    "papermill": {
     "duration": 0.035836,
     "end_time": "2021-08-13T07:16:36.620553",
     "exception": false,
     "start_time": "2021-08-13T07:16:36.584717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The goal of this notebook is to provide an overview of how write a notebook and create a submission file that successfully solves the churn prediction problem. Please download the datasets, unzip and place them in the same folder as this notebook.\n",
    "\n",
    "We are going to follow the process called CRISP-DM.\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b9/CRISP-DM_Process_Diagram.png/639px-CRISP-DM_Process_Diagram.png\" style=\"height: 400px; width:400px;\"/>\n",
    "\n",
    "After Business and Data Understanding via EDA, we want to prepare data for modelling. Then evaluate and submit our predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9290ee78",
   "metadata": {
    "papermill": {
     "duration": 0.034552,
     "end_time": "2021-08-13T07:16:36.690028",
     "exception": false,
     "start_time": "2021-08-13T07:16:36.655476",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 0. Problem statement\n",
    "\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    "For many incumbent operators, retaining high profitable customers is the number one business\n",
    "goal. To reduce customer churn, telecom companies need to predict which customers are at high risk of churn. In this project, you will analyze customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn, and identify the main indicators of churn.\n",
    "\n",
    "In this competition, your goal is *to build a machine learning model that is able to predict churning customers based on the features provided for their usage.*\n",
    "\n",
    "**Customer behaviour during churn:**\n",
    "\n",
    "Customers usually do not decide to switch to another competitor instantly, but rather over a\n",
    "period of time (this is especially applicable to high-value customers). In churn prediction, we\n",
    "assume that there are three phases of customer lifecycle :\n",
    "\n",
    "1. <u>The ‘good’ phase:</u> In this phase, the customer is happy with the service and behaves as usual.\n",
    "\n",
    "2. <u>The ‘action’ phase:</u> The customer experience starts to sore in this phase, for e.g. he/she gets a compelling offer from a competitor, faces unjust charges, becomes unhappy with service quality etc. In this phase, the customer usually shows different behaviour than the ‘good’ months. It is crucial to identify high-churn-risk customers in this phase, since some corrective actions can be taken at this point (such as matching the competitor’s offer/improving the service quality etc.)\n",
    "\n",
    "3. <u>The ‘churn’ phase:</u> In this phase, the customer is said to have churned. In this case, since you are working over a four-month window, the first two months are the ‘good’ phase, the third month is the ‘action’ phase, while the fourth month (September) is the ‘churn’ phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da713b1",
   "metadata": {
    "papermill": {
     "duration": 0.034501,
     "end_time": "2021-08-13T07:16:36.760335",
     "exception": false,
     "start_time": "2021-08-13T07:16:36.725834",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Loading dependencies & datasets\n",
    "\n",
    "Lets start by loading our dependencies. We can keep adding any imports to this cell block, as we write mode and mode code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e47254e",
   "metadata": {
    "papermill": {
     "duration": 1.362112,
     "end_time": "2021-08-13T07:16:38.158342",
     "exception": false,
     "start_time": "2021-08-13T07:16:36.796230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Data Structures\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "\n",
    "### For installing missingno library, type this command in terminal\n",
    "#pip install missingno\n",
    "\n",
    "import missingno as msno\n",
    "\n",
    "#Sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "#Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "\n",
    "#Others\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b3958e-ebd7-4e69-a2c5-01d5bc871ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d5046d0",
   "metadata": {
    "papermill": {
     "duration": 0.03468,
     "end_time": "2021-08-13T07:16:38.240579",
     "exception": false,
     "start_time": "2021-08-13T07:16:38.205899",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we load our datasets and the data dictionary file.\n",
    "\n",
    "The **train.csv** file contains both dependent and independent features, while the **test.csv** contains only the independent variables. \n",
    "\n",
    "So, for model selection, I will create our own train/test dataset from the **train.csv** and use the model to predict the solution using the features in unseen test.csv data for submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5474122",
   "metadata": {
    "papermill": {
     "duration": 0.044801,
     "end_time": "2021-08-13T07:16:38.320264",
     "exception": false,
     "start_time": "2021-08-13T07:16:38.275463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#COMMENT THIS SECTION INCASE RUNNING THIS NOTEBOOK LOCALLY\n",
    "\n",
    "#Checking the kaggle paths for the uploaded datasets\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b94d1d5",
   "metadata": {
    "papermill": {
     "duration": 2.591587,
     "end_time": "2021-08-13T07:16:40.948543",
     "exception": false,
     "start_time": "2021-08-13T07:16:38.356956",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69999, 172)\n",
      "(30000, 171)\n",
      "(30000, 2)\n",
      "(36, 2)\n"
     ]
    }
   ],
   "source": [
    "#INCASE RUNNING THIS LOCALLY, PASS THE RELATIVE PATH OF THE CSV FILES BELOW\n",
    "#(e.g. if files are in same folder as notebook, simple write \"train.csv\" as path)\n",
    "\n",
    "data = pd.read_csv(\"train.csv\")\n",
    "unseen = pd.read_csv(\"test.csv\")\n",
    "sample = pd.read_csv(\"sample.csv\")\n",
    "data_dict = pd.read_csv(\"data_dictionary.csv\")\n",
    "\n",
    "print(data.shape)\n",
    "print(unseen.shape)\n",
    "print(sample.shape)\n",
    "print(data_dict.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13614e3d",
   "metadata": {
    "papermill": {
     "duration": 0.035613,
     "end_time": "2021-08-13T07:16:41.020316",
     "exception": false,
     "start_time": "2021-08-13T07:16:40.984703",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "1. Lets analyze the data dictionary versus the churn dataset.\n",
    "2. The data dictonary contains a list of abbrevations which provide you all the information you need to understand what a specific feature/variable in the churn dataset represents\n",
    "3. Example: \n",
    "\n",
    "> \"arpu_7\" -> Average revenue per user + KPI for the month of July\n",
    ">\n",
    "> \"onnet_mou_6\" ->  All kind of calls within the same operator network + Minutes of usage voice calls + KPI for the month of June\n",
    ">\n",
    ">\"night_pck_user_8\" -> Scheme to use during specific night hours only + Prepaid service schemes called PACKS + KPI for the month of August\n",
    ">\n",
    ">\"max_rech_data_7\" -> Maximum + Recharge + Mobile internet + KPI for the month of July\n",
    "\n",
    "Its important to understand the definitions of each feature that you are working with, take notes on which feature you think might impact the churn rate of a user, and what sort of analysis could you do to understand the distribution of the feature better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfb4dc5",
   "metadata": {
    "papermill": {
     "duration": 0.067353,
     "end_time": "2021-08-13T07:16:41.123346",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.055993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acronyms</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CIRCLE_ID</td>\n",
       "      <td>Telecom circle area to which the customer belo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOC</td>\n",
       "      <td>Local calls  within same telecom circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>STD</td>\n",
       "      <td>STD calls  outside the calling circle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IC</td>\n",
       "      <td>Incoming calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OG</td>\n",
       "      <td>Outgoing calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>T2T</td>\n",
       "      <td>Operator T to T ie within same operator mobile...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>T2M</td>\n",
       "      <td>Operator T to other operator mobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>T2O</td>\n",
       "      <td>Operator T to other operator fixed line</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>T2F</td>\n",
       "      <td>Operator T to fixed lines of T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>T2C</td>\n",
       "      <td>Operator T to its own call center</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ARPU</td>\n",
       "      <td>Average revenue per user</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MOU</td>\n",
       "      <td>Minutes of usage  voice calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AON</td>\n",
       "      <td>Age on network  number of days the customer is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ONNET</td>\n",
       "      <td>All kind of calls within the same operator net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>OFFNET</td>\n",
       "      <td>All kind of calls outside the operator T network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ROAM</td>\n",
       "      <td>Indicates that customer is in roaming zone dur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SPL</td>\n",
       "      <td>Special calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ISD</td>\n",
       "      <td>ISD calls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RECH</td>\n",
       "      <td>Recharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NUM</td>\n",
       "      <td>Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>AMT</td>\n",
       "      <td>Amount in local currency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>MAX</td>\n",
       "      <td>Maximum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>DATA</td>\n",
       "      <td>Mobile internet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>3G</td>\n",
       "      <td>G network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>AV</td>\n",
       "      <td>Average</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>VOL</td>\n",
       "      <td>Mobile internet usage volume in MB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2G</td>\n",
       "      <td>G network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>PCK</td>\n",
       "      <td>Prepaid service schemes called  PACKS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NIGHT</td>\n",
       "      <td>Scheme to use during specific night hours only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MONTHLY</td>\n",
       "      <td>Service schemes with validity equivalent to a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SACHET</td>\n",
       "      <td>Service schemes with validity smaller than a m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>*.6</td>\n",
       "      <td>KPI for the month of June</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>*.7</td>\n",
       "      <td>KPI for the month of July</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>*.8</td>\n",
       "      <td>KPI for the month of August</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>FB_USER</td>\n",
       "      <td>Service scheme to avail services of Facebook a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>VBC</td>\n",
       "      <td>Volume based cost  when no specific scheme is ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Acronyms                                        Description\n",
       "0     CIRCLE_ID  Telecom circle area to which the customer belo...\n",
       "1           LOC            Local calls  within same telecom circle\n",
       "2           STD              STD calls  outside the calling circle\n",
       "3            IC                                     Incoming calls\n",
       "4            OG                                     Outgoing calls\n",
       "5           T2T  Operator T to T ie within same operator mobile...\n",
       "6       T2M                    Operator T to other operator mobile\n",
       "7       T2O                Operator T to other operator fixed line\n",
       "8       T2F                         Operator T to fixed lines of T\n",
       "9       T2C                      Operator T to its own call center\n",
       "10     ARPU                               Average revenue per user\n",
       "11      MOU                          Minutes of usage  voice calls\n",
       "12      AON      Age on network  number of days the customer is...\n",
       "13     ONNET     All kind of calls within the same operator net...\n",
       "14   OFFNET       All kind of calls outside the operator T network\n",
       "15         ROAM  Indicates that customer is in roaming zone dur...\n",
       "16       SPL                                         Special calls\n",
       "17      ISD                                              ISD calls\n",
       "18     RECH                                               Recharge\n",
       "19      NUM                                                 Number\n",
       "20      AMT                               Amount in local currency\n",
       "21      MAX                                                Maximum\n",
       "22     DATA                                        Mobile internet\n",
       "23       3G                                              G network\n",
       "24       AV                                                Average\n",
       "25      VOL                     Mobile internet usage volume in MB\n",
       "26       2G                                              G network\n",
       "27      PCK                  Prepaid service schemes called  PACKS\n",
       "28    NIGHT         Scheme to use during specific night hours only\n",
       "29  MONTHLY      Service schemes with validity equivalent to a ...\n",
       "30    SACHET     Service schemes with validity smaller than a m...\n",
       "31      *.6                              KPI for the month of June\n",
       "32      *.7                              KPI for the month of July\n",
       "33      *.8                            KPI for the month of August\n",
       "34      FB_USER  Service scheme to avail services of Facebook a...\n",
       "35      VBC      Volume based cost  when no specific scheme is ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91e8d29",
   "metadata": {
    "papermill": {
     "duration": 0.036844,
     "end_time": "2021-08-13T07:16:41.198447",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.161603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "For the purpose of this **starter notebook**, we I will restrict the dataset to only a small set of variables. \n",
    "\n",
    "The approach I use here is to understand each Acronym, figure our what variable might be important and filter out variable names based on the combinations of acrynoms using REGEX. So, if I want the total minutes a person has spent on outgoing calls, I need acronyms, TOTAL, OG and MOU. So corresponding regex is ```total.+og.+mou```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b62d9f",
   "metadata": {
    "papermill": {
     "duration": 0.06318,
     "end_time": "2021-08-13T07:16:41.298901",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.235721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = ['id','circle_id']\n",
    "total_amounts = [i for i in list(data.columns) if re.search('total.+amt',i)]\n",
    "total_outgoing_minutes = [i for i in list(data.columns) if re.search('total.+og.+mou',i)]\n",
    "offnetwork_minutes = [i for i in list(data.columns) if re.search('offnet',i)]\n",
    "average_revenue_3g = [i for i in list(data.columns) if re.search('arpu.+3g',i)]\n",
    "average_revenue_2g = [i for i in list(data.columns) if re.search('arpu.+2g',i)]\n",
    "volume_3g = [i for i in list(data.columns) if re.search('vol.+3g',i)]\n",
    "volume_2g = [i for i in list(data.columns) if re.search('vol.+2g',i)]\n",
    "age_on_network = [i for i in list(data.columns) if re.search('aon',i)]\n",
    "\n",
    "#Storing them in a single flat list\n",
    "variables = [*ids, \n",
    "             *total_amounts, \n",
    "             *total_outgoing_minutes, \n",
    "             *offnetwork_minutes, \n",
    "             *average_revenue_3g, \n",
    "             *average_revenue_2g,\n",
    "             *volume_3g,\n",
    "             *volume_2g,\n",
    "             *age_on_network, \n",
    "             'churn_probability']\n",
    "\n",
    "data = data[variables].set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d40bdb11",
   "metadata": {
    "papermill": {
     "duration": 0.066079,
     "end_time": "2021-08-13T07:16:41.401769",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.335690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circle_id</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>...</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>109</td>\n",
       "      <td>77</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>81.21</td>\n",
       "      <td>221.68</td>\n",
       "      <td>3.63</td>\n",
       "      <td>32.24</td>\n",
       "      <td>96.68</td>\n",
       "      <td>2.33</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>30.73</td>\n",
       "      <td>31.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.99</td>\n",
       "      <td>30.89</td>\n",
       "      <td>...</td>\n",
       "      <td>122.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>352.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>710</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>109</td>\n",
       "      <td>70</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>56.49</td>\n",
       "      <td>99.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>53.99</td>\n",
       "      <td>82.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109</td>\n",
       "      <td>160</td>\n",
       "      <td>240</td>\n",
       "      <td>130</td>\n",
       "      <td>76.03</td>\n",
       "      <td>95.98</td>\n",
       "      <td>53.84</td>\n",
       "      <td>68.76</td>\n",
       "      <td>78.48</td>\n",
       "      <td>50.23</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>982</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>109</td>\n",
       "      <td>290</td>\n",
       "      <td>136</td>\n",
       "      <td>122</td>\n",
       "      <td>63.26</td>\n",
       "      <td>42.94</td>\n",
       "      <td>15.76</td>\n",
       "      <td>56.99</td>\n",
       "      <td>38.11</td>\n",
       "      <td>9.63</td>\n",
       "      <td>...</td>\n",
       "      <td>35.12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>390.8</td>\n",
       "      <td>308.89</td>\n",
       "      <td>213.47</td>\n",
       "      <td>647</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    circle_id  total_rech_amt_6  total_rech_amt_7  total_rech_amt_8  \\\n",
       "id                                                                    \n",
       "0         109                77                65                10   \n",
       "1         109                 0               145                50   \n",
       "2         109                70               120                 0   \n",
       "3         109               160               240               130   \n",
       "4         109               290               136               122   \n",
       "\n",
       "    total_og_mou_6  total_og_mou_7  total_og_mou_8  offnet_mou_6  \\\n",
       "id                                                                 \n",
       "0            81.21          221.68            3.63         32.24   \n",
       "1             0.00           30.73           31.66          0.00   \n",
       "2            56.49           99.36            0.00         53.99   \n",
       "3            76.03           95.98           53.84         68.76   \n",
       "4            63.26           42.94           15.76         56.99   \n",
       "\n",
       "    offnet_mou_7  offnet_mou_8  ...  arpu_2g_7  arpu_2g_8  vol_3g_mb_6  \\\n",
       "id                              ...                                      \n",
       "0          96.68          2.33  ...        NaN        NaN          0.0   \n",
       "1          25.99         30.89  ...     122.08        NaN          0.0   \n",
       "2          82.05          0.00  ...        NaN        NaN          0.0   \n",
       "3          78.48         50.23  ...        NaN        NaN          0.0   \n",
       "4          38.11          9.63  ...      35.12        0.0          0.0   \n",
       "\n",
       "    vol_3g_mb_7  vol_3g_mb_8  vol_2g_mb_6  vol_2g_mb_7  vol_2g_mb_8   aon  \\\n",
       "id                                                                          \n",
       "0          0.00          0.0          0.0         0.00         0.00  1958   \n",
       "1          3.96          0.0          0.0       352.91         0.00   710   \n",
       "2          0.00          0.0          0.0         0.00         0.00   882   \n",
       "3          0.00          0.0          0.0         0.00         0.00   982   \n",
       "4          0.00          0.0        390.8       308.89       213.47   647   \n",
       "\n",
       "    churn_probability  \n",
       "id                     \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fb9add",
   "metadata": {
    "papermill": {
     "duration": 0.037694,
     "end_time": "2021-08-13T07:16:41.476864",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.439170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's look at each variable's datatype:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbd5d726",
   "metadata": {
    "papermill": {
     "duration": 0.064419,
     "end_time": "2021-08-13T07:16:41.578526",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.514107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 69999 entries, 0 to 69998\n",
      "Data columns (total 24 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   circle_id          69999 non-null  int64  \n",
      " 1   total_rech_amt_6   69999 non-null  int64  \n",
      " 2   total_rech_amt_7   69999 non-null  int64  \n",
      " 3   total_rech_amt_8   69999 non-null  int64  \n",
      " 4   total_og_mou_6     69999 non-null  float64\n",
      " 5   total_og_mou_7     69999 non-null  float64\n",
      " 6   total_og_mou_8     69999 non-null  float64\n",
      " 7   offnet_mou_6       67231 non-null  float64\n",
      " 8   offnet_mou_7       67312 non-null  float64\n",
      " 9   offnet_mou_8       66296 non-null  float64\n",
      " 10  arpu_3g_6          17568 non-null  float64\n",
      " 11  arpu_3g_7          17865 non-null  float64\n",
      " 12  arpu_3g_8          18417 non-null  float64\n",
      " 13  arpu_2g_6          17568 non-null  float64\n",
      " 14  arpu_2g_7          17865 non-null  float64\n",
      " 15  arpu_2g_8          18417 non-null  float64\n",
      " 16  vol_3g_mb_6        69999 non-null  float64\n",
      " 17  vol_3g_mb_7        69999 non-null  float64\n",
      " 18  vol_3g_mb_8        69999 non-null  float64\n",
      " 19  vol_2g_mb_6        69999 non-null  float64\n",
      " 20  vol_2g_mb_7        69999 non-null  float64\n",
      " 21  vol_2g_mb_8        69999 non-null  float64\n",
      " 22  aon                69999 non-null  int64  \n",
      " 23  churn_probability  69999 non-null  int64  \n",
      "dtypes: float64(18), int64(6)\n",
      "memory usage: 13.4 MB\n"
     ]
    }
   ],
   "source": [
    "data.info(verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f71a0be",
   "metadata": {
    "papermill": {
     "duration": 0.037487,
     "end_time": "2021-08-13T07:16:41.653911",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.616424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's also summarize the features using the df.describe method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ed1a2ee",
   "metadata": {
    "papermill": {
     "duration": 0.160583,
     "end_time": "2021-08-13T07:16:41.852218",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.691635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>circle_id</th>\n",
       "      <th>total_rech_amt_6</th>\n",
       "      <th>total_rech_amt_7</th>\n",
       "      <th>total_rech_amt_8</th>\n",
       "      <th>total_og_mou_6</th>\n",
       "      <th>total_og_mou_7</th>\n",
       "      <th>total_og_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>...</th>\n",
       "      <th>arpu_2g_7</th>\n",
       "      <th>arpu_2g_8</th>\n",
       "      <th>vol_3g_mb_6</th>\n",
       "      <th>vol_3g_mb_7</th>\n",
       "      <th>vol_3g_mb_8</th>\n",
       "      <th>vol_2g_mb_6</th>\n",
       "      <th>vol_2g_mb_7</th>\n",
       "      <th>vol_2g_mb_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69999.0</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>66296.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>109.0</td>\n",
       "      <td>328.139788</td>\n",
       "      <td>322.376363</td>\n",
       "      <td>323.846355</td>\n",
       "      <td>306.451436</td>\n",
       "      <td>310.572674</td>\n",
       "      <td>304.513065</td>\n",
       "      <td>198.874771</td>\n",
       "      <td>197.153383</td>\n",
       "      <td>196.543577</td>\n",
       "      <td>...</td>\n",
       "      <td>85.846074</td>\n",
       "      <td>86.348404</td>\n",
       "      <td>122.171882</td>\n",
       "      <td>128.934444</td>\n",
       "      <td>135.486541</td>\n",
       "      <td>51.773924</td>\n",
       "      <td>51.240204</td>\n",
       "      <td>50.127506</td>\n",
       "      <td>1220.639709</td>\n",
       "      <td>0.101887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>404.211068</td>\n",
       "      <td>411.070120</td>\n",
       "      <td>426.181405</td>\n",
       "      <td>465.502866</td>\n",
       "      <td>479.131770</td>\n",
       "      <td>477.936832</td>\n",
       "      <td>316.818355</td>\n",
       "      <td>322.482226</td>\n",
       "      <td>324.089234</td>\n",
       "      <td>...</td>\n",
       "      <td>178.067280</td>\n",
       "      <td>170.297094</td>\n",
       "      <td>554.869965</td>\n",
       "      <td>554.096072</td>\n",
       "      <td>568.310234</td>\n",
       "      <td>212.513909</td>\n",
       "      <td>211.114667</td>\n",
       "      <td>213.101403</td>\n",
       "      <td>952.426321</td>\n",
       "      <td>0.302502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>109.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.090000</td>\n",
       "      <td>-55.830000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>109.0</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>44.780000</td>\n",
       "      <td>42.910000</td>\n",
       "      <td>38.710000</td>\n",
       "      <td>34.860000</td>\n",
       "      <td>32.240000</td>\n",
       "      <td>31.575000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>109.0</td>\n",
       "      <td>229.000000</td>\n",
       "      <td>220.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>145.280000</td>\n",
       "      <td>141.230000</td>\n",
       "      <td>138.360000</td>\n",
       "      <td>96.480000</td>\n",
       "      <td>91.885000</td>\n",
       "      <td>91.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.800000</td>\n",
       "      <td>9.090000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>868.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>109.0</td>\n",
       "      <td>438.000000</td>\n",
       "      <td>430.000000</td>\n",
       "      <td>436.000000</td>\n",
       "      <td>374.305000</td>\n",
       "      <td>380.045000</td>\n",
       "      <td>370.895000</td>\n",
       "      <td>232.990000</td>\n",
       "      <td>227.630000</td>\n",
       "      <td>229.345000</td>\n",
       "      <td>...</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>122.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1813.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>109.0</td>\n",
       "      <td>35190.000000</td>\n",
       "      <td>40335.000000</td>\n",
       "      <td>45320.000000</td>\n",
       "      <td>10674.030000</td>\n",
       "      <td>8285.640000</td>\n",
       "      <td>14043.060000</td>\n",
       "      <td>8362.360000</td>\n",
       "      <td>7043.980000</td>\n",
       "      <td>14007.340000</td>\n",
       "      <td>...</td>\n",
       "      <td>4809.360000</td>\n",
       "      <td>3483.170000</td>\n",
       "      <td>45735.400000</td>\n",
       "      <td>28144.120000</td>\n",
       "      <td>30036.060000</td>\n",
       "      <td>10285.900000</td>\n",
       "      <td>7873.550000</td>\n",
       "      <td>11117.610000</td>\n",
       "      <td>4337.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       circle_id  total_rech_amt_6  total_rech_amt_7  total_rech_amt_8  \\\n",
       "count    69999.0      69999.000000      69999.000000      69999.000000   \n",
       "mean       109.0        328.139788        322.376363        323.846355   \n",
       "std          0.0        404.211068        411.070120        426.181405   \n",
       "min        109.0          0.000000          0.000000          0.000000   \n",
       "25%        109.0        110.000000        100.000000         90.000000   \n",
       "50%        109.0        229.000000        220.000000        225.000000   \n",
       "75%        109.0        438.000000        430.000000        436.000000   \n",
       "max        109.0      35190.000000      40335.000000      45320.000000   \n",
       "\n",
       "       total_og_mou_6  total_og_mou_7  total_og_mou_8  offnet_mou_6  \\\n",
       "count    69999.000000    69999.000000    69999.000000  67231.000000   \n",
       "mean       306.451436      310.572674      304.513065    198.874771   \n",
       "std        465.502866      479.131770      477.936832    316.818355   \n",
       "min          0.000000        0.000000        0.000000      0.000000   \n",
       "25%         44.780000       42.910000       38.710000     34.860000   \n",
       "50%        145.280000      141.230000      138.360000     96.480000   \n",
       "75%        374.305000      380.045000      370.895000    232.990000   \n",
       "max      10674.030000     8285.640000    14043.060000   8362.360000   \n",
       "\n",
       "       offnet_mou_7  offnet_mou_8  ...     arpu_2g_7     arpu_2g_8  \\\n",
       "count  67312.000000  66296.000000  ...  17865.000000  18417.000000   \n",
       "mean     197.153383    196.543577  ...     85.846074     86.348404   \n",
       "std      322.482226    324.089234  ...    178.067280    170.297094   \n",
       "min        0.000000      0.000000  ...    -13.090000    -55.830000   \n",
       "25%       32.240000     31.575000  ...      0.000000      0.000000   \n",
       "50%       91.885000     91.800000  ...      8.800000      9.090000   \n",
       "75%      227.630000    229.345000  ...    122.070000    122.070000   \n",
       "max     7043.980000  14007.340000  ...   4809.360000   3483.170000   \n",
       "\n",
       "        vol_3g_mb_6   vol_3g_mb_7   vol_3g_mb_8   vol_2g_mb_6   vol_2g_mb_7  \\\n",
       "count  69999.000000  69999.000000  69999.000000  69999.000000  69999.000000   \n",
       "mean     122.171882    128.934444    135.486541     51.773924     51.240204   \n",
       "std      554.869965    554.096072    568.310234    212.513909    211.114667   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max    45735.400000  28144.120000  30036.060000  10285.900000   7873.550000   \n",
       "\n",
       "        vol_2g_mb_8           aon  churn_probability  \n",
       "count  69999.000000  69999.000000       69999.000000  \n",
       "mean      50.127506   1220.639709           0.101887  \n",
       "std      213.101403    952.426321           0.302502  \n",
       "min        0.000000    180.000000           0.000000  \n",
       "25%        0.000000    468.000000           0.000000  \n",
       "50%        0.000000    868.000000           0.000000  \n",
       "75%        0.000000   1813.000000           0.000000  \n",
       "max    11117.610000   4337.000000           1.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717a47b1",
   "metadata": {
    "papermill": {
     "duration": 0.03869,
     "end_time": "2021-08-13T07:16:41.929599",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.890909",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Create X, y and then Train test split\n",
    "\n",
    "Lets create X and y datasets and skip \"circle_id\" since it has only 1 unique value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17d8d0f3",
   "metadata": {
    "papermill": {
     "duration": 0.04928,
     "end_time": "2021-08-13T07:16:42.017029",
     "exception": false,
     "start_time": "2021-08-13T07:16:41.967749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([109])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['circle_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd2a70a2",
   "metadata": {
    "papermill": {
     "duration": 0.054463,
     "end_time": "2021-08-13T07:16:42.111249",
     "exception": false,
     "start_time": "2021-08-13T07:16:42.056786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "drop() takes from 1 to 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcircle_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39miloc[:,:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      2\u001b[0m y \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      4\u001b[0m X\u001b[38;5;241m.\u001b[39mshape, y\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mTypeError\u001b[0m: drop() takes from 1 to 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "X = data.drop(['circle_id'], axis=1).iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1e9eca",
   "metadata": {
    "papermill": {
     "duration": 0.039731,
     "end_time": "2021-08-13T07:16:42.189842",
     "exception": false,
     "start_time": "2021-08-13T07:16:42.150111",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Splitting train and test data to avoid any contamination of the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19049f7a",
   "metadata": {
    "papermill": {
     "duration": 0.065525,
     "end_time": "2021-08-13T07:16:42.294433",
     "exception": false,
     "start_time": "2021-08-13T07:16:42.228908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383c1ddb",
   "metadata": {
    "papermill": {
     "duration": 0.068615,
     "end_time": "2021-08-13T07:16:42.402101",
     "exception": false,
     "start_time": "2021-08-13T07:16:42.333486",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a29fbf5",
   "metadata": {
    "papermill": {
     "duration": 0.039575,
     "end_time": "2021-08-13T07:16:42.482838",
     "exception": false,
     "start_time": "2021-08-13T07:16:42.443263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3. Handling Missing data\n",
    "\n",
    "First lets analyse the missing data. We can use missingno library for quick visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6360a919",
   "metadata": {
    "papermill": {
     "duration": 1.699725,
     "end_time": "2021-08-13T07:16:44.222465",
     "exception": false,
     "start_time": "2021-08-13T07:16:42.522740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "msno.bar(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1217cc5e",
   "metadata": {
    "papermill": {
     "duration": 0.995529,
     "end_time": "2021-08-13T07:16:45.259912",
     "exception": false,
     "start_time": "2021-08-13T07:16:44.264383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "msno.matrix(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d509008",
   "metadata": {
    "papermill": {
     "duration": 0.043599,
     "end_time": "2021-08-13T07:16:45.347986",
     "exception": false,
     "start_time": "2021-08-13T07:16:45.304387",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Lets also calculate the % missing data for each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910cbe80",
   "metadata": {
    "papermill": {
     "duration": 0.06183,
     "end_time": "2021-08-13T07:16:45.454014",
     "exception": false,
     "start_time": "2021-08-13T07:16:45.392184",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing_data_percent = 100*X_train.isnull().sum()/len(y_train)\n",
    "missing_data_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dbf492",
   "metadata": {
    "papermill": {
     "duration": 0.043963,
     "end_time": "2021-08-13T07:16:45.542693",
     "exception": false,
     "start_time": "2021-08-13T07:16:45.498730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since too much missing information would make a column not really a great predictor for churn, we drop these columns and keep only the ones which have less than 40% missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c195c",
   "metadata": {
    "papermill": {
     "duration": 0.054309,
     "end_time": "2021-08-13T07:16:45.641625",
     "exception": false,
     "start_time": "2021-08-13T07:16:45.587316",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "new_vars = missing_data_percent[missing_data_percent.le(40)].index\n",
    "new_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1935c440",
   "metadata": {
    "papermill": {
     "duration": 0.05574,
     "end_time": "2021-08-13T07:16:45.742430",
     "exception": false,
     "start_time": "2021-08-13T07:16:45.686690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_filtered = X_train[new_vars]\n",
    "X_train_filtered.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60c8a2f",
   "metadata": {
    "papermill": {
     "duration": 0.045444,
     "end_time": "2021-08-13T07:16:45.832903",
     "exception": false,
     "start_time": "2021-08-13T07:16:45.787459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we try imputation on variables with any amount of missing data still left. There are multiple ways of imputing data, and each will require a good business understanding of what the missing data is and how you may handle it.\n",
    "\n",
    "Some tips while working with missing data - \n",
    "\n",
    "1. Can simply replace missing values directly with a constant value such as 0\n",
    "2. In certain cases you may want to replace it with the average value for each column respectively\n",
    "3. For timeseries data, you may consider using linear or spline interplolation between a set of points, if you have data available for some of the months, and missing for the others.\n",
    "4. You can consider more advance methods for imputation such as MICE.\n",
    "\n",
    "In our case, I will just demostrate a simple imputation with constant values as zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ece2cff",
   "metadata": {
    "papermill": {
     "duration": 0.056957,
     "end_time": "2021-08-13T07:16:45.935041",
     "exception": false,
     "start_time": "2021-08-13T07:16:45.878084",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "missing_data_percent = X_train_filtered.isnull().any()\n",
    "impute_cols = missing_data_percent[missing_data_percent.gt(0)].index\n",
    "impute_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1574ed",
   "metadata": {
    "papermill": {
     "duration": 0.085462,
     "end_time": "2021-08-13T07:16:46.065826",
     "exception": false,
     "start_time": "2021-08-13T07:16:45.980364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy='constant', fill_value=0)\n",
    "X_train_filtered[impute_cols] = imp.fit_transform(X_train_filtered[impute_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb20d440",
   "metadata": {
    "papermill": {
     "duration": 0.914023,
     "end_time": "2021-08-13T07:16:47.025018",
     "exception": false,
     "start_time": "2021-08-13T07:16:46.110995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "msno.bar(X_train_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdac87cc",
   "metadata": {
    "papermill": {
     "duration": 0.132076,
     "end_time": "2021-08-13T07:16:47.205627",
     "exception": false,
     "start_time": "2021-08-13T07:16:47.073551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9857d0c5",
   "metadata": {
    "papermill": {
     "duration": 0.047951,
     "end_time": "2021-08-13T07:16:47.301731",
     "exception": false,
     "start_time": "2021-08-13T07:16:47.253780",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4. Exploratory Data Analysis & Preprocessing\n",
    "\n",
    "Lets start by analysing the univariate distributions of each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea7d58e",
   "metadata": {
    "papermill": {
     "duration": 0.885464,
     "end_time": "2021-08-13T07:16:48.234798",
     "exception": false,
     "start_time": "2021-08-13T07:16:47.349334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.xticks(rotation=45)\n",
    "sns.boxplot(data = X_train_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "381045b0",
   "metadata": {
    "papermill": {
     "duration": 0.050148,
     "end_time": "2021-08-13T07:16:48.336611",
     "exception": false,
     "start_time": "2021-08-13T07:16:48.286463",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4.1 Handling outliers\n",
    "\n",
    "The box plots of these features show there a lot of outliers. These can be capped with k-sigma method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8ffc1c",
   "metadata": {
    "papermill": {
     "duration": 0.058225,
     "end_time": "2021-08-13T07:16:48.444315",
     "exception": false,
     "start_time": "2021-08-13T07:16:48.386090",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cap_outliers(array, k=3):\n",
    "    upper_limit = array.mean() + k*array.std()\n",
    "    lower_limit = array.mean() - k*array.std()\n",
    "    array[array<lower_limit] = lower_limit\n",
    "    array[array>upper_limit] = upper_limit\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d1d43d",
   "metadata": {
    "papermill": {
     "duration": 0.995019,
     "end_time": "2021-08-13T07:16:49.488905",
     "exception": false,
     "start_time": "2021-08-13T07:16:48.493886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train_filtered1 = X_train_filtered.apply(cap_outliers, axis=0)\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.xticks(rotation=45)\n",
    "sns.boxplot(data = X_train_filtered1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872e86fe",
   "metadata": {
    "papermill": {
     "duration": 0.050821,
     "end_time": "2021-08-13T07:16:49.590800",
     "exception": false,
     "start_time": "2021-08-13T07:16:49.539979",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 4.2 Feature scaling\n",
    "\n",
    "Lets also scale the features by scaling them with Standard scaler (few other alternates are min-max scaling and Z-scaling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad7ad33",
   "metadata": {
    "papermill": {
     "duration": 0.077522,
     "end_time": "2021-08-13T07:16:49.720148",
     "exception": false,
     "start_time": "2021-08-13T07:16:49.642626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "X_train_filtered2 = scale.fit_transform(X_train_filtered1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4473651",
   "metadata": {
    "papermill": {
     "duration": 0.893696,
     "end_time": "2021-08-13T07:16:50.665247",
     "exception": false,
     "start_time": "2021-08-13T07:16:49.771551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.xticks(rotation=45)\n",
    "sns.boxplot(data = pd.DataFrame(X_train_filtered2, columns=new_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc94753",
   "metadata": {
    "papermill": {
     "duration": 0.053477,
     "end_time": "2021-08-13T07:16:50.772231",
     "exception": false,
     "start_time": "2021-08-13T07:16:50.718754",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can perform feature transformations at this stage. \n",
    "\n",
    "1. **Positively skewed:** Common transformations of this data include square root, cube root, and log.\n",
    "2. **Negatively skewed:** Common transformations include square, cube root and logarithmic.\n",
    "\n",
    "Please read the following link to understand how to perform feature scaling and preprocessing : https://scikit-learn.org/stable/modules/preprocessing.html\n",
    " \n",
    "Lets also plot the correlations for each feature for bivariate analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cb0bbc",
   "metadata": {
    "papermill": {
     "duration": 0.568818,
     "end_time": "2021-08-13T07:16:51.394261",
     "exception": false,
     "start_time": "2021-08-13T07:16:50.825443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(pd.DataFrame(X_train_filtered2, columns=new_vars).corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f0109",
   "metadata": {
    "papermill": {
     "duration": 0.393552,
     "end_time": "2021-08-13T07:16:51.843093",
     "exception": false,
     "start_time": "2021-08-13T07:16:51.449541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Distribution for the churn probability\n",
    "sns.histplot(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59e12c1",
   "metadata": {
    "papermill": {
     "duration": 0.054582,
     "end_time": "2021-08-13T07:16:51.952415",
     "exception": false,
     "start_time": "2021-08-13T07:16:51.897833",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5. Feature engineering and selection\n",
    "\n",
    "Let's understand feature importances for raw features as well as components to decide top features for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8746dc3f",
   "metadata": {
    "papermill": {
     "duration": 8.035233,
     "end_time": "2021-08-13T07:17:00.041999",
     "exception": false,
     "start_time": "2021-08-13T07:16:52.006766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "rf.fit(X_train_filtered2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a268bb0",
   "metadata": {
    "papermill": {
     "duration": 0.165618,
     "end_time": "2021-08-13T07:17:00.262949",
     "exception": false,
     "start_time": "2021-08-13T07:17:00.097331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({'col':new_vars, 'importance':rf.feature_importances_})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc97e26",
   "metadata": {
    "papermill": {
     "duration": 0.295789,
     "end_time": "2021-08-13T07:17:00.614769",
     "exception": false,
     "start_time": "2021-08-13T07:17:00.318980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.xticks(rotation=45)\n",
    "plt.bar(feature_importances['col'], feature_importances['importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914c5bec",
   "metadata": {
    "papermill": {
     "duration": 0.055776,
     "end_time": "2021-08-13T07:17:00.727093",
     "exception": false,
     "start_time": "2021-08-13T07:17:00.671317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "At this step, you can create a bunch of features based on business understanding, such as \n",
    "1. \"average % gain of 3g volume from month 6 to 8\" - (growth or decline of 3g usage month over month?)\n",
    "2. \"ratio of total outgoing amount and age of user on network\" - (average daily usage of a user?)\n",
    "3. \"standard deviation of the total amount paid by user for all services\" - (too much variability in charges?)\n",
    "4. etc..\n",
    "\n",
    "Another way of finding good features would be to project them into a lower dimensional space using PCA. PCA creates components which are a linear combination of the features. This then allows you to select components which explain the highest amount of variance.\n",
    "\n",
    "Lets try to project the data onto 2D space and plot. **Note:** you can try TSNE, which is another dimensionality reduction approach as well. Check https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html for moree details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2687e7a",
   "metadata": {
    "papermill": {
     "duration": 4.617268,
     "end_time": "2021-08-13T07:17:05.400295",
     "exception": false,
     "start_time": "2021-08-13T07:17:00.783027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca_components = pca.fit_transform(X_train_filtered2)\n",
    "sns.scatterplot(x=pca_components[:,0], y=pca_components[:,1], hue=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad202938",
   "metadata": {
    "papermill": {
     "duration": 2.631052,
     "end_time": "2021-08-13T07:17:08.093002",
     "exception": false,
     "start_time": "2021-08-13T07:17:05.461950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x=pca_components[:,1], y=pca_components[:,2], hue=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b9b83e",
   "metadata": {
    "papermill": {
     "duration": 0.063551,
     "end_time": "2021-08-13T07:17:08.224795",
     "exception": false,
     "start_time": "2021-08-13T07:17:08.161244",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's also check which of the components have high feature importances towards the end goal of churn prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586937b3",
   "metadata": {
    "papermill": {
     "duration": 12.694325,
     "end_time": "2021-08-13T07:17:20.982792",
     "exception": false,
     "start_time": "2021-08-13T07:17:08.288467",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "rf.fit(pca_components, y_train)\n",
    "\n",
    "feature_importances = pd.DataFrame({'col':['component_'+str(i) for i in range(16)], \n",
    "                                    'importance':rf.feature_importances_})\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.xticks(rotation=45)\n",
    "plt.bar(feature_importances['col'], feature_importances['importance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa1235",
   "metadata": {
    "papermill": {
     "duration": 0.065189,
     "end_time": "2021-08-13T07:17:21.113066",
     "exception": false,
     "start_time": "2021-08-13T07:17:21.047877",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Model building\n",
    "\n",
    "Let's build a quick model with logistic regression and the first 2 PCA components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f08df2",
   "metadata": {
    "papermill": {
     "duration": 0.185674,
     "end_time": "2021-08-13T07:17:21.364082",
     "exception": false,
     "start_time": "2021-08-13T07:17:21.178408",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter=1000, tol=0.001, solver='sag')\n",
    "lr.fit(pca_components[:,:2], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775e57ca",
   "metadata": {
    "papermill": {
     "duration": 0.089994,
     "end_time": "2021-08-13T07:17:21.519838",
     "exception": false,
     "start_time": "2021-08-13T07:17:21.429844",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lr.score(pca_components[:,:2], y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321b0b34",
   "metadata": {
    "papermill": {
     "duration": 0.064818,
     "end_time": "2021-08-13T07:17:21.699674",
     "exception": false,
     "start_time": "2021-08-13T07:17:21.634856",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model has 89.8% accuracy, but let's build a pipeline to fit and score the model faster.\n",
    "\n",
    "The steps of this pipeline would be the following, but this is only one type of pipeline -\n",
    "1. Imputation\n",
    "2. Scaling\n",
    "3. PCA\n",
    "4. Classification model\n",
    "\n",
    "You can change this pipeline, add addition transformations, change models, use cross validation or even use this pipeline to work with a Gridsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d915ec",
   "metadata": {
    "papermill": {
     "duration": 0.071699,
     "end_time": "2021-08-13T07:17:21.836592",
     "exception": false,
     "start_time": "2021-08-13T07:17:21.764893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "imp = SimpleImputer(strategy='constant', fill_value=0)\n",
    "scale = StandardScaler()\n",
    "pca = PCA(n_components=10)\n",
    "lr = LogisticRegression(max_iter=1000, tol=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0defd3",
   "metadata": {
    "papermill": {
     "duration": 0.073281,
     "end_time": "2021-08-13T07:17:21.975259",
     "exception": false,
     "start_time": "2021-08-13T07:17:21.901978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [('imputation',imp),\n",
    "                         ('scaling',scale),\n",
    "                         ('pca',pca),\n",
    "                         ('model',lr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8972c5fd",
   "metadata": {
    "papermill": {
     "duration": 0.485922,
     "end_time": "2021-08-13T07:17:22.526693",
     "exception": false,
     "start_time": "2021-08-13T07:17:22.040771",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe.fit(X_train[new_vars], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441b2354",
   "metadata": {
    "papermill": {
     "duration": 0.111563,
     "end_time": "2021-08-13T07:17:22.755300",
     "exception": false,
     "start_time": "2021-08-13T07:17:22.643737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_score = pipe.score(X_train[new_vars], y_train)\n",
    "print(\"Training accuracy:\", train_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3db02c7",
   "metadata": {
    "papermill": {
     "duration": 0.087891,
     "end_time": "2021-08-13T07:17:22.960566",
     "exception": false,
     "start_time": "2021-08-13T07:17:22.872675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_score = pipe.score(X_test[new_vars], y_test)\n",
    "print(\"Test accuracy:\", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beec9d12",
   "metadata": {
    "papermill": {
     "duration": 0.070399,
     "end_time": "2021-08-13T07:17:23.152879",
     "exception": false,
     "start_time": "2021-08-13T07:17:23.082480",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's make a confusion matrix to analyze how each class is being predicted by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012c5a58",
   "metadata": {
    "papermill": {
     "duration": 0.200569,
     "end_time": "2021-08-13T07:17:23.421831",
     "exception": false,
     "start_time": "2021-08-13T07:17:23.221262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_train, pipe.predict(X_train[new_vars]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba50bf",
   "metadata": {
    "papermill": {
     "duration": 0.109186,
     "end_time": "2021-08-13T07:17:23.608435",
     "exception": false,
     "start_time": "2021-08-13T07:17:23.499249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, pipe.predict(X_test[new_vars]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff7895f",
   "metadata": {
    "papermill": {
     "duration": 0.068268,
     "end_time": "2021-08-13T07:17:23.788669",
     "exception": false,
     "start_time": "2021-08-13T07:17:23.720401",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can see a high amount of type 2 error. Due to class imbalance, the model is clearly trying to predict majority of the cases as class 0. Understanding how to handle class imbalance in classification models might be the key to winning this competition :) (hint!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407cfc13",
   "metadata": {
    "papermill": {
     "duration": 0.09953,
     "end_time": "2021-08-13T07:17:23.955991",
     "exception": false,
     "start_time": "2021-08-13T07:17:23.856461",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "precision_score(y_test, pipe.predict(X_test[new_vars]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb37be6",
   "metadata": {
    "papermill": {
     "duration": 0.123943,
     "end_time": "2021-08-13T07:17:24.198308",
     "exception": false,
     "start_time": "2021-08-13T07:17:24.074365",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "recall_score(y_test, pipe.predict(X_test[new_vars]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1e1eef",
   "metadata": {
    "papermill": {
     "duration": 0.067672,
     "end_time": "2021-08-13T07:17:24.385001",
     "exception": false,
     "start_time": "2021-08-13T07:17:24.317329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Creating submission file\n",
    "\n",
    "For submission, we need to make sure that the format is exactly the same as the sample.csv file. It contains 2 columns, id and churn_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad672d46",
   "metadata": {
    "papermill": {
     "duration": 0.080814,
     "end_time": "2021-08-13T07:17:24.533810",
     "exception": false,
     "start_time": "2021-08-13T07:17:24.452996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020d3949",
   "metadata": {
    "papermill": {
     "duration": 0.068381,
     "end_time": "2021-08-13T07:17:24.670628",
     "exception": false,
     "start_time": "2021-08-13T07:17:24.602247",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The submission file should contain churn_probability values that have to be predicted for the unseen data provided (test.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb95d9d",
   "metadata": {
    "papermill": {
     "duration": 0.098877,
     "end_time": "2021-08-13T07:17:24.838199",
     "exception": false,
     "start_time": "2021-08-13T07:17:24.739322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unseen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9eb3a2",
   "metadata": {
    "papermill": {
     "duration": 0.06952,
     "end_time": "2021-08-13T07:17:24.977086",
     "exception": false,
     "start_time": "2021-08-13T07:17:24.907566",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Lets first select the columns that we want to work with (or create them, if you have done any feature engineering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530c384a",
   "metadata": {
    "papermill": {
     "duration": 0.093498,
     "end_time": "2021-08-13T07:17:25.140420",
     "exception": false,
     "start_time": "2021-08-13T07:17:25.046922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_data = unseen.set_index('id')[new_vars]\n",
    "submission_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d584eab9",
   "metadata": {
    "papermill": {
     "duration": 0.069588,
     "end_time": "2021-08-13T07:17:25.279867",
     "exception": false,
     "start_time": "2021-08-13T07:17:25.210279",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, lets create a new column in the unseen dataset called churn_probability and use the model pipeline to predict the probabilities for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2459d7",
   "metadata": {
    "papermill": {
     "duration": 0.108369,
     "end_time": "2021-08-13T07:17:25.457668",
     "exception": false,
     "start_time": "2021-08-13T07:17:25.349299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "unseen['churn_probability'] = pipe.predict(submission_data)\n",
    "output = unseen[['id','churn_probability']]\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc053f",
   "metadata": {
    "papermill": {
     "duration": 0.124336,
     "end_time": "2021-08-13T07:17:25.701056",
     "exception": false,
     "start_time": "2021-08-13T07:17:25.576720",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, lets create a csv file out of this dataset, ensuring to set index=False to avoid an addition column in the csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0ce11a",
   "metadata": {
    "papermill": {
     "duration": 0.12837,
     "end_time": "2021-08-13T07:17:25.914318",
     "exception": false,
     "start_time": "2021-08-13T07:17:25.785948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output.to_csv('submission_pca_lr_13jul.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc24e68",
   "metadata": {
    "papermill": {
     "duration": 0.08214,
     "end_time": "2021-08-13T07:17:26.080507",
     "exception": false,
     "start_time": "2021-08-13T07:17:25.998367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can now take this file and upload it as a submission on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a688423",
   "metadata": {
    "papermill": {
     "duration": 0.070782,
     "end_time": "2021-08-13T07:17:26.223247",
     "exception": false,
     "start_time": "2021-08-13T07:17:26.152465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 57.533667,
   "end_time": "2021-08-13T07:17:27.204430",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-08-13T07:16:29.670763",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
